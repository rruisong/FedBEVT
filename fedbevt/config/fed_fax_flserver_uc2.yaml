name: uc2
root_dir: '/data/uc2/train'
test_dir: '/data/uc2/test'

# network assumption
network:
  straggler_ratio: 0

# client configuration
clients:
  num_clients: 4
  client_list: ["client_1", "client_2", "client_3", "client_4"]
  client_1:
    attribute: 'bus'
    camera_idx: [0,1,2,3]
  client_2:
    attribute: 'truck'
    camera_idx: [0,1,2,3]
  client_3:
    attribute: 'car'
    camera_idx: [0,1,2,3]
  client_4:
    attribute: 'car'
    camera_idx: [0,1,2,3]


# hyperparameters
train_params:
  batch_size: &batch_size 1
  epoches: &epoches 1 # number of local epochs 
  num_rounds: &num_rounds 500 # number of total communication number 
  eval_freq: 1 # evalution frequency
  save_freq: 1 # model saving frequency
  max_cav: &max_cav 1 # we condier perception task on single CAV in this paper
  visible: true 


fusion:
  core_method: 'CamLateFusionDataset'
  args: []


data_augment: []
add_data_extension: ['bev_dynamic.png', 'bev_static.png', 'bev_lane.png', 'bev_visibility.png']

# preprocess parameters
preprocess:
  core_method: 'RgbPreprocessor'
  args:
    bgr2rgb: true
    resize_x: &image_width 512
    resize_y: &image_height 512
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  # object evaluation range
  cav_lidar_range: &cav_lidar [-50, -50, -3, 50, 50, 1]


# anchor box
postprocess:
  core_method: 'CameraBevPostprocessor'
  anchor_args:
    cav_lidar_range: *cav_lidar
  order: 'hwl' 
  max_num: 100 # maximum number of objects in a single frame.
  nms_thresh: 0.15

# model parameters, we use fax attention architecture for transformer-based model
model:
  core_method: fax_fused_transformer
  args:
    target: &target 'dynamic'
    encoder:
      num_layers: 34
      pretrained: true
      image_width: *image_width
      image_height: *image_height
      id_pick: [1, 2, 3]

    decoder:
      input_dim: 128
      num_layer: 3
      num_ch_dec: &decoder_block [32, 64, 128]

    fax:
      dim: [128, 128, 128] # b 256 h w from resenet
      middle: [2, 2, 2]
      bev_embedding:
        sigma: 1.0
        bev_height: 256
        bev_width: 256
        h_meters: 100
        w_meters: 100
        offset: 0.0
        upsample_scales: [2, 4, 8]

      cross_view: 
        image_height: *image_height
        image_width: *image_width
        no_image_features: False
        skip: True
        heads: [4, 4, 4]
        dim_head: [32, 32, 32]
        qkv_bias: True

      cross_view_swap:
        rel_pos_emb: False
        q_win_size: [ [ 16, 16 ], [ 16, 16 ], [ 32, 32 ] ]
        feat_win_size: [ [ 8, 8 ], [ 8, 8 ], [ 16, 16 ] ]
        bev_embedding_flag: [ true, false, false ]

      self_attn:
        dim_head: 32
        dropout: 0.1
        window_size: 32


    seg_head_dim: 32
    output_class: 2

loss:
  core_method: vanilla_seg_loss
  args:
    target: *target
    d_weights: 75.0
    s_weights: 15.0
    d_coe: 2.0
    s_coe: 0.0

optimizer:
  core_method: AdamW
  lr: 2e-4
  args:
    eps: 1e-10
    weight_decay: 1e-2

lr_scheduler:
    core_method: cosineannealwarm
    epoches: *epoches
    num_rounds: *num_rounds
    warmup_lr: 2e-5
    warmup_epoches: 10
    lr_min: 5e-6

